{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfmwTaIC7H1xj2yKDtGXEs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Read in Data"],"metadata":{"id":"84Mu78hSIgXU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAYQOguYISgr"},"outputs":[],"source":["import pandas as pd\n","x_train = pd.read_csv('X_train.csv')\n","x_test = pd.read_csv('X_val.csv')\n","y_train = pd.read_csv('y_train.csv')\n","y_test = pd.read_csv('y_val.csv')"]},{"cell_type":"markdown","source":["#Model definitions"],"metadata":{"id":"FLhDd-WTJfVC"}},{"cell_type":"code","source":["#Installation\n","!pip install interpret -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSsKlDlaJ79O","executionInfo":{"status":"ok","timestamp":1680542793310,"user_tz":-60,"elapsed":13912,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"e46826f7-27a7-4b70-a338-830f8efe2362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m758.0/758.0 KB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 KB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 KB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from pandas.core.window.rolling import numba_notes\n","#Regression Models\n","from sklearn.linear_model import ElasticNet\n","from sklearn.ensemble import GradientBoostingRegressor as XGBRegressor\n","#Linear Regression \n","from sklearn.linear_model import LinearRegression\n","lm = LinearRegression()\n","#Ridge Regression \n","from sklearn import linear_model\n","ridge = linear_model.Ridge(alpha=.99)\n","#Lasso Regression\n","from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n","lasso = linear_model.Lasso(alpha=0.0)\n","#KNeighborsRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","neigh = KNeighborsRegressor(n_neighbors=3, weights='distance')\n","#Random Forrest\n","from sklearn.ensemble import RandomForestRegressor\n","rf = RandomForestRegressor(max_depth=30, max_features='auto', min_samples_leaf=4)\n","#Decision Trees\n","from sklearn.tree import DecisionTreeRegressor\n","dt = DecisionTreeRegressor(max_depth=3, max_features='auto', min_samples_leaf=3, min_weight_fraction_leaf=0.2)\n","#SVM - SVR\n","from sklearn import svm\n","SVM = svm.SVR()\n","#Gradient Boosting Regressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","gbr = GradientBoostingRegressor(learning_rate = 0.02, n_estimators = 80, random_state=0)\n","# XGBoost\n","import xgboost as xg\n","xgb = xg.XGBRegressor(learning_rate = 0.1, max_depth = 10, n_estimators = 100)\n","# EBM\n","from interpret import show\n","from interpret.data import Marginal\n","from interpret.glassbox import ExplainableBoostingRegressor, LinearRegression, RegressionTree\n","ebm = ExplainableBoostingRegressor(interactions=100)"],"metadata":{"id":"966xAJrBJg51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"qGHuI_fYN9VR","executionInfo":{"status":"ok","timestamp":1680543955710,"user_tz":-60,"elapsed":4,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"c3accb0f-ebe3-4ae6-a32a-a7e672de9165"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       country  team  season  md  outcome  Cluster  win  goals        gd  \\\n","0            4   154    2018  13        1        0    0    0.2  0.500000   \n","1            4   179    2010  19        1        0    0    0.1  0.500000   \n","2            2    31    2006   6        0        2    0    0.0  0.444444   \n","3            4    29    2013  18        2        2    1    0.1  0.555556   \n","4            1   170    2004  24        2        0    1    0.2  0.611111   \n","...        ...   ...     ...  ..      ...      ...  ...    ...       ...   \n","54752        2     2    2006   1        2        0    1    0.3  0.666667   \n","54753        3   157    2016  16        2        2    1    0.2  0.555556   \n","54754        4   142    2019  37        0        2    0    0.1  0.444444   \n","54755        2   189    2012  13        0        0    0    0.0  0.333333   \n","54756        1    28    2010  10        1        0    0    0.1  0.500000   \n","\n","         opp_gd  avg_starter_age      win%  \n","0      0.500000         0.531856  0.076923  \n","1      0.500000         0.443609  0.105263  \n","2      0.555556         0.511278  0.500000  \n","3      0.444444         0.514170  0.888889  \n","4      0.388889         0.444976  0.375000  \n","...         ...              ...       ...  \n","54752  0.333333         0.506073  1.000000  \n","54753  0.444444         0.470588  0.562500  \n","54754  0.555556         0.561404  0.270270  \n","54755  0.666667         0.534413  0.307692  \n","54756  0.500000         0.614035  0.000000  \n","\n","[54757 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-5d121a95-e387-4471-b92f-308950698d16\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","      <th>team</th>\n","      <th>season</th>\n","      <th>md</th>\n","      <th>outcome</th>\n","      <th>Cluster</th>\n","      <th>win</th>\n","      <th>goals</th>\n","      <th>gd</th>\n","      <th>opp_gd</th>\n","      <th>avg_starter_age</th>\n","      <th>win%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>154</td>\n","      <td>2018</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.2</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.531856</td>\n","      <td>0.076923</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>179</td>\n","      <td>2010</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.1</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.443609</td>\n","      <td>0.105263</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>31</td>\n","      <td>2006</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.444444</td>\n","      <td>0.555556</td>\n","      <td>0.511278</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>29</td>\n","      <td>2013</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0.1</td>\n","      <td>0.555556</td>\n","      <td>0.444444</td>\n","      <td>0.514170</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>2004</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>0.611111</td>\n","      <td>0.388889</td>\n","      <td>0.444976</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54752</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2006</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.3</td>\n","      <td>0.666667</td>\n","      <td>0.333333</td>\n","      <td>0.506073</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>54753</th>\n","      <td>3</td>\n","      <td>157</td>\n","      <td>2016</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>0.555556</td>\n","      <td>0.444444</td>\n","      <td>0.470588</td>\n","      <td>0.562500</td>\n","    </tr>\n","    <tr>\n","      <th>54754</th>\n","      <td>4</td>\n","      <td>142</td>\n","      <td>2019</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.1</td>\n","      <td>0.444444</td>\n","      <td>0.555556</td>\n","      <td>0.561404</td>\n","      <td>0.270270</td>\n","    </tr>\n","    <tr>\n","      <th>54755</th>\n","      <td>2</td>\n","      <td>189</td>\n","      <td>2012</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.333333</td>\n","      <td>0.666667</td>\n","      <td>0.534413</td>\n","      <td>0.307692</td>\n","    </tr>\n","    <tr>\n","      <th>54756</th>\n","      <td>1</td>\n","      <td>28</td>\n","      <td>2010</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.1</td>\n","      <td>0.500000</td>\n","      <td>0.500000</td>\n","      <td>0.614035</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54757 rows × 12 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d121a95-e387-4471-b92f-308950698d16')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5d121a95-e387-4471-b92f-308950698d16 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5d121a95-e387-4471-b92f-308950698d16');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["y_train = y_train.values"],"metadata":{"id":"GeC2u3odN_dK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmksYVXMPLGd","executionInfo":{"status":"ok","timestamp":1680544209772,"user_tz":-60,"elapsed":2,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"f579eb3f-c86a-4ff3-e535-a4fb6f73e1f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["y_train[0:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wiL5l0GPkvR","executionInfo":{"status":"ok","timestamp":1680544268399,"user_tz":-60,"elapsed":795,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"c6a7f117-731a-4e86-c446-58278c1b03b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.04359431],\n","       [0.04537367]])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["y_train.values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PsFy1CbP4Rg","executionInfo":{"status":"ok","timestamp":1680544406481,"user_tz":-60,"elapsed":2,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"f1a8636a-0079-4319-eb23-4b5312a4ba60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.04359431],\n","       [0.04537367],\n","       [0.12279804],\n","       ...,\n","       [0.12597865],\n","       [0.06205516],\n","       [0.00907473]])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["x_train.values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VH8GqR3Pan8","executionInfo":{"status":"ok","timestamp":1680544396889,"user_tz":-60,"elapsed":421,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"4a933465-a1f0-4cde-d0d9-75b49db5971e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.00000000e+00, 1.54000000e+02, 2.01800000e+03, ...,\n","        5.00000000e-01, 5.31855956e-01, 7.69230769e-02],\n","       [4.00000000e+00, 1.79000000e+02, 2.01000000e+03, ...,\n","        5.00000000e-01, 4.43609023e-01, 1.05263158e-01],\n","       [2.00000000e+00, 3.10000000e+01, 2.00600000e+03, ...,\n","        5.55555556e-01, 5.11278195e-01, 5.00000000e-01],\n","       ...,\n","       [4.00000000e+00, 1.42000000e+02, 2.01900000e+03, ...,\n","        5.55555556e-01, 5.61403509e-01, 2.70270270e-01],\n","       [2.00000000e+00, 1.89000000e+02, 2.01200000e+03, ...,\n","        6.66666667e-01, 5.34412955e-01, 3.07692308e-01],\n","       [1.00000000e+00, 2.80000000e+01, 2.01000000e+03, ...,\n","        5.00000000e-01, 6.14035088e-01, 0.00000000e+00]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["type(x_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmVMiYyMPT_M","executionInfo":{"status":"ok","timestamp":1680544225922,"user_tz":-60,"elapsed":2,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"59ba8779-e146-48f4-a9c1-3bf9c9f414dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["x_train[0:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBtvU0iIPp0m","executionInfo":{"status":"ok","timestamp":1680544282757,"user_tz":-60,"elapsed":4,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"e71a1773-ac6e-4b41-bc2c-686625848790"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.00000000e+00, 1.54000000e+02, 2.01800000e+03, 1.30000000e+01,\n","        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e-01,\n","        5.00000000e-01, 5.00000000e-01, 5.31855956e-01, 7.69230769e-02],\n","       [4.00000000e+00, 1.79000000e+02, 2.01000000e+03, 1.90000000e+01,\n","        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e-01,\n","        5.00000000e-01, 5.00000000e-01, 4.43609023e-01, 1.05263158e-01]])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from math import sqrt\n","x_train_here = x_train.values\n","y_train_here = y_train.values\n","x_train_here"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kDJlJNqNPg4","executionInfo":{"status":"ok","timestamp":1680544675074,"user_tz":-60,"elapsed":5,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"d9b418a3-cfe1-4479-b1a3-a5d1bd209a53"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.00000000e+00, 1.54000000e+02, 2.01800000e+03, ...,\n","        5.00000000e-01, 5.31855956e-01, 7.69230769e-02],\n","       [4.00000000e+00, 1.79000000e+02, 2.01000000e+03, ...,\n","        5.00000000e-01, 4.43609023e-01, 1.05263158e-01],\n","       [2.00000000e+00, 3.10000000e+01, 2.00600000e+03, ...,\n","        5.55555556e-01, 5.11278195e-01, 5.00000000e-01],\n","       ...,\n","       [4.00000000e+00, 1.42000000e+02, 2.01900000e+03, ...,\n","        5.55555556e-01, 5.61403509e-01, 2.70270270e-01],\n","       [2.00000000e+00, 1.89000000e+02, 2.01200000e+03, ...,\n","        6.66666667e-01, 5.34412955e-01, 3.07692308e-01],\n","       [1.00000000e+00, 2.80000000e+01, 2.01000000e+03, ...,\n","        5.00000000e-01, 6.14035088e-01, 0.00000000e+00]])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["y_train_here"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-vS1PAOQ6YG","executionInfo":{"status":"ok","timestamp":1680544660076,"user_tz":-60,"elapsed":735,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"a822c8a8-2cc5-46cd-e15f-abc59fcdc0b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.04359431],\n","       [0.04537367],\n","       [0.12279804],\n","       ...,\n","       [0.12597865],\n","       [0.06205516],\n","       [0.00907473]])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["models = [lasso,  rf, dt, SVM, gbr, xgb, ebm] #lm, ridge, neigh\n","labels = ['Lasso', 'Random Forrest', 'Deision Tree', 'SVM', 'Gradient Boosting', 'XGBoost', 'EBM'] # 'Linear', 'Ridge', 'KNN'"],"metadata":{"id":"N0LUmobeMI3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqb4z-aCMi1V","executionInfo":{"status":"ok","timestamp":1680547381421,"user_tz":-60,"elapsed":3,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"0f5053c5-009c-48eb-f9b8-ca1c61d58564"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Lasso(alpha=0.0),\n"," RandomForestRegressor(max_depth=30, max_features='auto', min_samples_leaf=4),\n"," DecisionTreeRegressor(max_depth=3, max_features='auto', min_samples_leaf=3,\n","                       min_weight_fraction_leaf=0.2),\n"," SVR(),\n"," GradientBoostingRegressor(learning_rate=0.02, n_estimators=80, random_state=0),\n"," XGBRegressor(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=10, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n","              predictor=None, random_state=None, ...),\n"," ExplainableBoostingRegressor(interactions=100)]"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["x_train_here.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYkTv6pZRkwQ","executionInfo":{"status":"ok","timestamp":1680545253791,"user_tz":-60,"elapsed":1,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"444b7ff9-f9b1-473d-dcc5-d11f77947af8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(54757, 12)"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["y_train_here.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7o2H4G3eRou4","executionInfo":{"status":"ok","timestamp":1680545252930,"user_tz":-60,"elapsed":3,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"cc861428-72b3-46e3-d851-2817d9f2b428"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(54757, 1)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["from mlxtend.regressor import StackingCVRegressor\n","stack = StackingCVRegressor(regressors=models,\n","                            meta_regressor=xg.XGBRegressor(n_estimators=60, max_depth = 3, learning_rate = 0.2), \n","                            cv=10,\n","                            use_features_in_secondary=True,\n","                            store_train_meta_features=True,\n","                            shuffle=False\n","                           )"],"metadata":{"id":"KzsHta20Moht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stack.fit(x_train_here, y_train_here)\n","pred = stack.predict(x_test)\n","score_mae = mean_absolute_error(y_test, pred)\n","score_mse = mean_squared_error(y_test, pred)\n","score_r2=r2_score(y_test, pred)*100\n","score_rmse =  sqrt(score_mse)\n","print('Model: {0}, MAE: {1}'.format(type(stack).__name__, score_mae))\n","print('Model: {0}, MSE: {1}'.format(type(stack).__name__, score_mse))\n","print('Model: {0}, RMSE: {1}'.format(type(stack).__name__, score_rmse))\n","print('Model: {0}, R2: {1}'.format(type(stack).__name__, score_r2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"na6b52S7Q2Mf","executionInfo":{"status":"ok","timestamp":1680548239152,"user_tz":-60,"elapsed":853744,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"1e4ec0b2-e439-4c66-fb98-57a873a29dfe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+02, tolerance: 5.455e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+02, tolerance: 5.428e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+02, tolerance: 5.463e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+02, tolerance: 5.426e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+02, tolerance: 5.440e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+02, tolerance: 5.440e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+02, tolerance: 5.409e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+02, tolerance: 5.421e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+02, tolerance: 5.484e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+02, tolerance: 5.407e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:180: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  instance.fit(X[train_idx], y[train_idx])\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:207: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  regr.fit(X, y)\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+02, tolerance: 6.041e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.9/dist-packages/mlxtend/regressor/stacking_cv_regression.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  regr.fit(X, y)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but Lasso was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SVR was fitted without feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model: StackingCVRegressor, MAE: 0.011308244385590485\n","Model: StackingCVRegressor, MSE: 0.00036526766097287\n","Model: StackingCVRegressor, RMSE: 0.01911197689860654\n","Model: StackingCVRegressor, R2: 96.4251398940928\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["stacking_results = []\n","stacking_results.append({'Model': 'Stacked Model', 'Mean Absolute Error': score_mae, 'Mean Squared Error': score_mse, 'RMSE': score_rmse,'R-squared': score_r2})\n","\n","df = pd.DataFrame(stacking_results)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"n6km1mHNe1C7","executionInfo":{"status":"ok","timestamp":1680548302962,"user_tz":-60,"elapsed":374,"user":{"displayName":"Sam Ryder","userId":"16473918676889113572"}},"outputId":"da05cb2e-1f11-46a6-e508-7fb8b3874a93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Model  Mean Absolute Error  Mean Squared Error      RMSE  R-squared\n","0  Stacked Model             0.011308            0.000365  0.019112   96.42514"],"text/html":["\n","  <div id=\"df-639fb673-ac84-4e95-9dfc-7ee203629e1e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Mean Absolute Error</th>\n","      <th>Mean Squared Error</th>\n","      <th>RMSE</th>\n","      <th>R-squared</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Stacked Model</td>\n","      <td>0.011308</td>\n","      <td>0.000365</td>\n","      <td>0.019112</td>\n","      <td>96.42514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-639fb673-ac84-4e95-9dfc-7ee203629e1e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-639fb673-ac84-4e95-9dfc-7ee203629e1e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-639fb673-ac84-4e95-9dfc-7ee203629e1e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":66}]}]}